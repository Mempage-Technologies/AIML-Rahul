{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fashion MNIST multi-class classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "here we are going to classify differnt types of clothes from each other. <br>\n",
    "You can read more about the dataset on the following link.<br>\n",
    "https://www.tensorflow.org/datasets/catalog/fashion_mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing the required modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "tfds.disable_progress_bar()\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading the dataset and viewing an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "(ds_train, ds_test), ds_info = tfds.load(\"fashion_mnist\", \n",
    "                    split=['train', 'test'],\n",
    "                    shuffle_files=True,\n",
    "                    as_supervised=True,\n",
    "                    with_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 4\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for example in ds_train.take(1):\n",
    "    image, label = example[0], example[1]\n",
    "    plt.imshow(image.numpy()[:, :, 0].astype(np.float32), cmap=plt.get_cmap(\"gray\"))\n",
    "    print(\"Label: %d\" % label.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preparing the dataset as train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train set creation\n",
    "\n",
    "def normalize_image(image, label):\n",
    "    return tf.cast(image, tf.float32)/255., label\n",
    "\n",
    "ds_train = ds_train.map(normalize_image, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "ds_train = ds_train.cache()\n",
    "ds_train = ds_train.shuffle(ds_info.splits[\"train\"].num_examples)\n",
    "ds_train = ds_train.batch(128)\n",
    "ds_train = ds_train.prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test set creation\n",
    "ds_test = ds_test.map(\n",
    "    normalize_image, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "ds_test = ds_test.batch(128)\n",
    "ds_test = ds_test.cache()\n",
    "ds_test = ds_test.prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Callback function for stopping training when desired accuracy is reached and for tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "#custom callback for stopping training\n",
    "class MyCallback(tf.keras.callbacks.Callback):\n",
    "    #implementing the on_epoch_end function to stop training when accuracy reaches more than 90%\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if(logs.get(\"accuracy\") > 0.95):\n",
    "            print(\"Accuracy is greater than 95%. Stopping training!\")\n",
    "            self.model.stop_training = True\n",
    "\n",
    "#tensorboard callback\n",
    "logs_dir = \".\\logs\\\\fit\\\\\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "board_callback = tf.keras.callbacks.TensorBoard(log_dir=logs_dir)\n",
    "my_callback = MyCallback()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_13 (Flatten)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 101,770\n",
      "Trainable params: 101,770\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "        \n",
    "        tf.keras.layers.Flatten(input_shape=(28, 28, 1)),\n",
    "        tf.keras.layers.Dense(128, activation=tf.keras.activations.relu),\n",
    "        tf.keras.layers.Dense(10, activation=tf.keras.activations.softmax)\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "469/469 [==============================] - 6s 12ms/step - loss: 0.5611 - accuracy: 0.8080 - val_loss: 0.4889 - val_accuracy: 0.8283\n",
      "Epoch 2/10\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.4108 - accuracy: 0.8559 - val_loss: 0.4493 - val_accuracy: 0.8457\n",
      "Epoch 3/10\n",
      "469/469 [==============================] - 15s 31ms/step - loss: 0.3712 - accuracy: 0.8675 - val_loss: 0.4042 - val_accuracy: 0.8606\n",
      "Epoch 4/10\n",
      "469/469 [==============================] - 7s 16ms/step - loss: 0.3462 - accuracy: 0.8766 - val_loss: 0.3901 - val_accuracy: 0.8617\n",
      "Epoch 5/10\n",
      "469/469 [==============================] - 7s 14ms/step - loss: 0.3237 - accuracy: 0.8832 - val_loss: 0.3781 - val_accuracy: 0.8681\n",
      "Epoch 6/10\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 0.3076 - accuracy: 0.8879 - val_loss: 0.3908 - val_accuracy: 0.8584\n",
      "Epoch 7/10\n",
      "469/469 [==============================] - 5s 10ms/step - loss: 0.2957 - accuracy: 0.8923 - val_loss: 0.3808 - val_accuracy: 0.8627\n",
      "Epoch 8/10\n",
      "469/469 [==============================] - 9s 19ms/step - loss: 0.2855 - accuracy: 0.8963 - val_loss: 0.3565 - val_accuracy: 0.8761\n",
      "Epoch 9/10\n",
      "469/469 [==============================] - 13s 27ms/step - loss: 0.2732 - accuracy: 0.9006 - val_loss: 0.3699 - val_accuracy: 0.8698\n",
      "Epoch 10/10\n",
      "469/469 [==============================] - 6s 13ms/step - loss: 0.2650 - accuracy: 0.9026 - val_loss: 0.3409 - val_accuracy: 0.8822\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1ef18ce9088>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#compiling the model\n",
    "model.compile(optimizer = \"adam\",\n",
    "             loss = \"sparse_categorical_crossentropy\",\n",
    "             metrics=['accuracy']\n",
    "             )\n",
    "\n",
    "#train the model\n",
    "model.fit(ds_train,\n",
    "          epochs = 10,\n",
    "          validation_data = ds_test,\n",
    "          verbose = 1,\n",
    "          callbacks = [my_callback, board_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 5788), started 0:01:03 ago. (Use '!kill 5788' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-1dc17390fe43aa83\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-1dc17390fe43aa83\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          url.port = 6006;\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir=logs/fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     79/Unknown - 1s 8ms/step - loss: 0.3409 - accuracy: 0.8822"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3408978571997413, 0.8822]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(ds_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Accuracy: 90.26<br>\n",
    "Testing Accuracy: 88.22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
